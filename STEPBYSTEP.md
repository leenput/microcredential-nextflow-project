# STEP BY STEP PROJECT OVERVIEW 
## overview of requirements and nice to haves
**Requirements**
* Should be on Github (Please add the link to projects.md)
* Docker and Apptainer compatibility (bonus points if also conda compatible) of all modules
* Should contain at least 3 modules from tools that weren't covered during the training
* at least 1 module should contain a custom script
* at least 1 module should contain an external tool
* Should contain at least 1 config profile
* Should not need any prior setup (the pipeline should work out-of-the-box on the infrastructure used during the training) with minimal test data
* Should output relevant files to an output directory
* Should contain at least 3 different operators

**Nice to haves**
* Process resources should be managed in the nextflow.config using process labels
* Follow the nf-core best practice guidelines
* The pipeline contains a subworkflow


## Define project scope, tools to use, and  required input data
### Project scope 
I will develop a nextflow pipeline for preprocessing human genome sequencing data generated by Oxford Nanopore Technologies. I will implement the following steps and a final bash script that evaluates metrics:
- Step 0: Basecalling (will skip this because this requires gpus and not sure how to configure that)
- Step 1: QC of ONT reads after basecalling using NanoPlot
- Step 2: ONT read filtering based on read quality and length using Chopper
- Step 3: read mapping against the T2T genome using minimap2, followed by sorting and indexing using samtools 
- Step 4: QC of read mapping using NanoPlot and mosdepth
- Step 5: Script to screen QC parameters and give green light or warning if some parameters dont meet the filter criteria to proceed with pipeline. 

### Tools to use
- [Nanoplot][https://github.com/wdecoster/NanoPlot]
- [Chopper][https://github.com/wdecoster/chopper]
- [Minimap2][https://github.com/lh3/minimap2]
- [Samtools][https://www.htslib.org/]
- [Mosdepth][https://github.com/brentp/mosdepth]
- custom bash script 

### Input data 
- Human reference genome
- Some fastq files as test data

## Setting up
**STEP 1: Start local github repository where we will start building the nextflow pipeline**
To already try to adhere to the nf-core best practice guidelines, I installed nf-core on my laptop and used the template to initiate my nextflow project locally, which also initiates git. 
```
nf-core pipelines create
```
I navigate into the project folder ont-preprocessing and inspect it. Many files that seem a bit too complicated for now, but will try to use the framework as much as possible.

**STEP 2: Link pipeline to remote GitHub repository**
On GitHub profile, i made a new github repository ([leenaput/nextflow-microcredential][https://github.com/leenput/nextflow-microcredential]).
On my local system, I linked the local git project to this repository:
```
git@github.com:leenput/nextflow-microcredential.git
git push --all origin
```

## Prepare input test data
Create directory to store input fastq data in
```
mkdir data
```
copy chromosome of T2T reference genome (T2T-CHM13v2) fasta file (Chr21) and fastq test data here.
(Ideally reference genome retrieved using the igenome config and getGenomeAttributes subworkflow supplied by nf-core template.)

## Create modules per tool
first create a modules directory
```
mkdir modules
```

### 1. QC module - nanoplot
Find appropriate **conda enviroments/containers**.
- conda: https://anaconda.org/bioconda/nanoplot
- container: I find a recent one on quai.io biocontainers: quay.io/biocontainers/nanoplot:1.44.1--pyhdfd78af_0

**Define inputs**: the tool takes raw/filtered fastq or ubam files (with --fastq flag) or sorted and mapped bam files (with --bam). 
Therefore, we need to define two seperate processes, one for read QC and one for mapping QC. 
In main.nf we need to include the nanoplot.nf module for NANOPLOT_RAW process as QC_RAW, QC_FILT to use it twice, and the NANOPLOT_BAM for read alignment QC 

As module input: tuple of sample name and reads and a step value
-> match this in main.nf by defining appropriate channel that is shaped like a tuple with three elements (sample, reads-filepath, step)
-> we can use the *map operator* for this

**Define outputs**: the tool generates a bunch of different file formats (html, png, txt, log), so we should specify and emit them in the output section. 

### 2. read processing module - chopper
Find appropriate **conda enviroments/containers**.
- conda: https://anaconda.org/bioconda/chopper
- container: quai.io biocontainers: quay.io/biocontainers/chopper:0.10.0--hcdda2d0_0

**Define inputs**: the tool takes fastq reads as an input (--input), and optional filtering criteria. We will use the quality score (--quality) and length (--minlength) as filters
As module input: tuple of sample name and reads, qscore value and length value
--> match in main.nf by setting up value channels for qscore and length 
--> feed chopper module with reads channel, qscore and length value channels

**Define outputs**: The tool outputs a filtered fastq file, which we will emit, to then use as input for post-processing QC step and for alignment.

### 3. alignment module - minimap2